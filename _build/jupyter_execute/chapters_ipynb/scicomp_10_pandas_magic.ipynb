{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reduction and analysis magic with `Pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "In the previous lesson we covered some of the basics of `pandas`:\n",
    "- creating dataframes from series(es)\n",
    "- writing a dataframe to file\n",
    "- reading a dataframe from file\n",
    "- accessing rows and columns within a dataframe\n",
    "- accessing subsets of data within a dataframe based on values meeting some conditions\n",
    "- creating new columns in a dataframe \n",
    "\n",
    "If you're like most people, you're probably thinking \"Wow, that is all very fancy (*i.e.*, confusing), but I'll stick with my Excel spreadsheets, k thx bye.\"  In this lesson, we'll see some of the true magic of `pandas` that makes it (or something like it) an essential tool for meaningful data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Data analysis is an incredibly powerful way of knowing things.  In general, the larger a dataset is (the more \"robust\" it is), the more confident we can be that the results derived from that dataset are significant.  We want to be confident that our results reflect general features fo the system we're studying and not some weird statistical fluctuation, and *big* datasets are generally the way to achieve this.  \n",
    "\n",
    "For example, it would be a bad idea to study the average height of human beings by looking at a dataset containing the heights of only the 5 starting players on the 2023 Denver Nuggests basketball team.  Big datasets are important for making sure that we're doing careful science.\n",
    "\n",
    "That said, quanttative data in large amounts can be difficult for us humans to process.  If you opened a spreadsheet containing, say, 5 rows of human height data you might be able to glance through the individual heights, ballpark the average height at 6'8\", and determine that something is really funky with the data.  (\"Are these people all pro basketbal players?\")  If, however, you opened a spreadsheet containing height measurements for all of the 12.96 million residents of the state of Pennsylvania your eyes might glaze over in panic and you might just trust whatever results a researcher derived from the data.  Large amounts of data are simply overwhelming to our squishy human brains.\n",
    "\n",
    "A beautiful illustration of this is the 2021 scientific misconduct scandal surrounding Dan Ariely, a Duke University Professor of Psychology and popular science author.  Ariely rose to national attention due in part to really good-sounding \"results\" from studies of human behavior, many of which focused on honesty.  In 2021, a team of data sleuths at Data Colada uncovered rather blatant data fabrication and manipulation in Ariely's work.  Ariely's subterfuge relied on the assumption that the dataset he was working with was too big for anyone to ever want to check his math.  Oops!\n",
    "\n",
    "There are many great articles about this online.  I strongly recommend learning more about this, as it's a great example of how not to do science.\n",
    "- Planet Money. [Did two honesty researchers fabricate their data?](https://open.spotify.com/episode/2Bse6AcwmJdHRE1hesMUxD?si=lWZfomnqQS-GyhtEPvj1-A)\n",
    "- Data Colada. [Evidence of Fraud in an Influential Field Experiment About Dishonesty](https://datacolada.org/98)\n",
    "- The New Yorker. [They Studied Dishonesty. Was Their Work a Lie?](https://www.newyorker.com/magazine/2023/10/09/they-studied-dishonesty-was-their-work-a-lie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Data reduction\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Data_reduction) tells us that \n",
    "\n",
    "> **Data reduction** is the transformation of numerical or alphabetical digital information derived empirically or experimentally into a corrected, ordered, and simplified form. The purpose of data reduction can be two-fold: reduce the number of data records by eliminating invalid data or *produce summary data and statistics at different aggregation levels for various applications*.\n",
    "\n",
    "The italicized text is what we're after here.  In previous lessons, we've learned how to do things like fit models to data to generate results.  Data reduction is the process that happens before that.  Data reduction often means taking a large amount of raw data and collapsing, massaging, and processing it into a smaller set of data from which we can generate results.  The term \"data reduction\" seems to have been replaced with the more general \"data analysis,\" but it's good to know what reduction is a particular step in many scientific processes.\n",
    "\n",
    "`Pandas` is an amazing tool for data reduction.  It can do quite easily some things that MS Excel (and similar) would just cry about.  We'll investigate these capabilities with a fairly easy-to-understand example.\n",
    "\n",
    "### Netflix data\n",
    "\n",
    "On 12 Dec 2023 Netflix [broke its silence](https://about.netflix.com/en/news/what-we-watched-a-netflix-engagement-report) about the popularity of content on its platform between.  Prior to this, Netflix would rank its top performers, but wouldn't release any absolute data on how much people watched each show/movie what it calls \"engagement\".  The report that Netflix released gives viewership information for titles between January and June of 2023.  A `csv` file of this data exists in the `data_files/` directory.  Let's load it up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "netflix_df = pd.read_csv('data_files/netflix_engagement_report_2023jan-jun.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a fairly big dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Available Globally?</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Hours Viewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arrested Development: Season 1</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>17,600,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arrested Development: Season 3</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>7,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arrested Development: Season 2</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>11,300,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trailer Park Boys: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>5,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trailer Park Boys: Season 2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>5,800,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trailer Park Boys: Season 4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>6,800,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Trailer Park Boys: Season 3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>6,800,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Trailer Park Boys: Season 5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>8,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Trailer Park Boys: Season 7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>7,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trailer Park Boys: Season 6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>4,800,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title Available Globally? Release Date   \n",
       "0  Arrested Development: Season 1                  No   2010-04-01  \\\n",
       "1  Arrested Development: Season 3                  No   2010-04-01   \n",
       "2  Arrested Development: Season 2                  No   2010-04-01   \n",
       "3     Trailer Park Boys: Season 1                 Yes   2010-09-22   \n",
       "4     Trailer Park Boys: Season 2                 Yes   2010-09-22   \n",
       "5     Trailer Park Boys: Season 4                 Yes   2010-09-22   \n",
       "6     Trailer Park Boys: Season 3                 Yes   2010-09-22   \n",
       "7     Trailer Park Boys: Season 5                 Yes   2010-09-22   \n",
       "8     Trailer Park Boys: Season 7                 Yes   2011-03-01   \n",
       "9     Trailer Park Boys: Season 6                 Yes   2011-03-01   \n",
       "\n",
       "  Hours Viewed  \n",
       "0   17,600,000  \n",
       "1    7,000,000  \n",
       "2   11,300,000  \n",
       "3    5,400,000  \n",
       "4    5,800,000  \n",
       "5    6,800,000  \n",
       "6    6,800,000  \n",
       "7    8,400,000  \n",
       "8    7,500,000  \n",
       "9    4,800,000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Available Globally?</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Hours Viewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18204</th>\n",
       "      <td>Špindl</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18205</th>\n",
       "      <td>Żyć nie umierać</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18206</th>\n",
       "      <td>الناموس: Season 1</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18207</th>\n",
       "      <td>حكايات بنات الجزء ١: Season 2</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18208</th>\n",
       "      <td>حكايات بنات الجزء ١: Season 3</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18209</th>\n",
       "      <td>راس السنة</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18210</th>\n",
       "      <td>心が叫びたがってるんだ。</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18211</th>\n",
       "      <td>두근두근 내 인생</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18212</th>\n",
       "      <td>라디오 스타</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18213</th>\n",
       "      <td>선생 김봉두</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title Available Globally? Release Date   \n",
       "18204                         Špindl                  No          NaN  \\\n",
       "18205                Żyć nie umierać                  No          NaN   \n",
       "18206              الناموس: Season 1                  No          NaN   \n",
       "18207  حكايات بنات الجزء ١: Season 2                  No          NaN   \n",
       "18208  حكايات بنات الجزء ١: Season 3                  No          NaN   \n",
       "18209                      راس السنة                  No          NaN   \n",
       "18210                   心が叫びたがってるんだ。                  No          NaN   \n",
       "18211                      두근두근 내 인생                  No          NaN   \n",
       "18212                         라디오 스타                  No          NaN   \n",
       "18213                         선생 김봉두                  No          NaN   \n",
       "\n",
       "      Hours Viewed  \n",
       "18204      100,000  \n",
       "18205      100,000  \n",
       "18206      100,000  \n",
       "18207      100,000  \n",
       "18208      100,000  \n",
       "18209      100,000  \n",
       "18210      100,000  \n",
       "18211      100,000  \n",
       "18212      100,000  \n",
       "18213      100,000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18214, 4)\n"
     ]
    }
   ],
   "source": [
    "display(netflix_df.head(10))\n",
    "display(netflix_df.tail(10))\n",
    "\n",
    "print(netflix_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so the dataframe contains title, availability, premier/release date, and hours watched for... 18,214 titles!  Yikes!  It also looks like the titles are ordered by the date that they became available, which is perhaps not super convenient.  It **is** nice to see *Arrested Development*, though!  Note that there are titles with non-Enlgish characters in them -- cool!  There are also titles that don't have a release date; `NaN` is pythonic for 'not a number'.\n",
    "\n",
    "You can maybe guess why a dataset like this might be very helpful to a company.  If they can determine features of the most-watched shows and find a way to make more of the same for less money, they can make ~~more crap that maximizes shareholder value~~ art that helps us understand what it means to be human.  Still, though, we need to do some analysis on this dataset in order to extract meaning/understanding from it.\n",
    "\n",
    "***\n",
    "\n",
    "### What do we want to know?\n",
    "\n",
    "At this point, I think that it will be helpful to establish a few research questions that we can investigate with this dataset.  \n",
    "\n",
    "1. What was the most-viewed title during this period?\n",
    "2. What's more popular, TV shows or movies?\n",
    "3. What was the total watch time for the titles in this dataset?\n",
    "4. How many unique properties are there in the dataset?  (*I.e.*, multiple seasons of the same show count as a single property.)\n",
    "5. **Brainstorm as a group and add your questions here!**\n",
    "\n",
    "What we want to know will guide which tools we use.\n",
    "\n",
    "***\n",
    "\n",
    "### `apply`\n",
    "\n",
    "#### `apply` example 1\n",
    "\n",
    "First, you may notice that the Hours Viewed column is a total pain -- Netflix has presented these large numbers with commas in them, which means that they appear in the dataframe as strings.  We need to fix this by producing a column of numerical values.\n",
    "\n",
    "Let's begin by writing a function which converts a single string such as this to an integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.234567"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_bad_number(s):\n",
    "    s = s.replace(',','') # replaces commas with nothing\n",
    "    n = int(s) / 1e6      # unit conversion, divides by 1 million\n",
    "    return n\n",
    "\n",
    "convert_bad_number('1,234,567') # let's test this function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  It would be really convenient if we could just apply this to an entire column of the dataframe to produce a new column.  Let's test this out in the cell below (uncomment the code and run the cell):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netflix_df['megahours_viewed'] = convert_bad_number(netflix_df['Hours Viewed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh nuts!  Well, maybe we should have expected that.  \n",
    "\n",
    "If the data were stored in something like a list, we would probably write a loop over the list to apply our function to the elements in succession.  This is possible with a dataframe but it is *incredibly* slow, so I'm not even going to show you how to do it.\n",
    "\n",
    "One **good** way to apply a function to each element of a column in a dataframe is to use the `Dataframe.apply` function.  We'll create the new column by `apply`-ing our function to the appropriate column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Available Globally?</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Hours Viewed</th>\n",
       "      <th>megahours_viewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arrested Development: Season 1</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>17,600,000</td>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arrested Development: Season 3</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>7,000,000</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arrested Development: Season 2</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>11,300,000</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trailer Park Boys: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>5,400,000</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trailer Park Boys: Season 2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>5,800,000</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trailer Park Boys: Season 4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>6,800,000</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Trailer Park Boys: Season 3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>6,800,000</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Trailer Park Boys: Season 5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>8,400,000</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Trailer Park Boys: Season 7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>7,500,000</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trailer Park Boys: Season 6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>4,800,000</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title Available Globally? Release Date   \n",
       "0  Arrested Development: Season 1                  No   2010-04-01  \\\n",
       "1  Arrested Development: Season 3                  No   2010-04-01   \n",
       "2  Arrested Development: Season 2                  No   2010-04-01   \n",
       "3     Trailer Park Boys: Season 1                 Yes   2010-09-22   \n",
       "4     Trailer Park Boys: Season 2                 Yes   2010-09-22   \n",
       "5     Trailer Park Boys: Season 4                 Yes   2010-09-22   \n",
       "6     Trailer Park Boys: Season 3                 Yes   2010-09-22   \n",
       "7     Trailer Park Boys: Season 5                 Yes   2010-09-22   \n",
       "8     Trailer Park Boys: Season 7                 Yes   2011-03-01   \n",
       "9     Trailer Park Boys: Season 6                 Yes   2011-03-01   \n",
       "\n",
       "  Hours Viewed  megahours_viewed  \n",
       "0   17,600,000              17.6  \n",
       "1    7,000,000               7.0  \n",
       "2   11,300,000              11.3  \n",
       "3    5,400,000               5.4  \n",
       "4    5,800,000               5.8  \n",
       "5    6,800,000               6.8  \n",
       "6    6,800,000               6.8  \n",
       "7    8,400,000               8.4  \n",
       "8    7,500,000               7.5  \n",
       "9    4,800,000               4.8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "netflix_df['megahours_viewed'] = netflix_df['Hours Viewed'].apply(convert_bad_number)\n",
    "\n",
    "display(netflix_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey, looking good!\n",
    "\n",
    "I should mention quickly that, while this is a valid way to do this, it is usually not the computationally *quickest* way to do it.  But it's fine for our purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `apply` example 2\n",
    "\n",
    "The release date is also pretty interesting, but it's a bit difficult to work with.  Let's try to make a column that gives the number of days between the release date and the end of the viewing period (30 June 2023).  We'll do the same type of thing that we did above: write a function and `apply` it to a column.\n",
    "\n",
    "I'm going to use the `datetime` module to speed things up.  If you haven't worked with `datetime` before, that's fine.  Read through the function and see if you can figure how it works.  Note that we have to build in a conditional for those titles that don't have a release date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "def calc_age(release_date):\n",
    "    if pd.isna(release_date): # if the release date is NaN\n",
    "        return None\n",
    "    else:\n",
    "        release_date = release_date.split('-') # split the string\n",
    "        release_date = date(int(release_date[0]), int(release_date[1]), int(release_date[2]))\n",
    "        end_date = date(2023, 6, 30) # set the end date\n",
    "        delta = end_date - release_date # calculate the difference between dates\n",
    "        return(delta.days + 1) # add 1 so that we don't divide by zero later!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply this function to the appropriate column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Available Globally?</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Hours Viewed</th>\n",
       "      <th>megahours_viewed</th>\n",
       "      <th>age_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arrested Development: Season 1</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>17,600,000</td>\n",
       "      <td>17.6</td>\n",
       "      <td>4839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arrested Development: Season 3</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>7,000,000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arrested Development: Season 2</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>11,300,000</td>\n",
       "      <td>11.3</td>\n",
       "      <td>4839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trailer Park Boys: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>5,400,000</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trailer Park Boys: Season 2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>5,800,000</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trailer Park Boys: Season 4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>6,800,000</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Trailer Park Boys: Season 3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>6,800,000</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Trailer Park Boys: Season 5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>8,400,000</td>\n",
       "      <td>8.4</td>\n",
       "      <td>4665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Trailer Park Boys: Season 7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>7,500,000</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trailer Park Boys: Season 6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>4,800,000</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4505.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title Available Globally? Release Date   \n",
       "0  Arrested Development: Season 1                  No   2010-04-01  \\\n",
       "1  Arrested Development: Season 3                  No   2010-04-01   \n",
       "2  Arrested Development: Season 2                  No   2010-04-01   \n",
       "3     Trailer Park Boys: Season 1                 Yes   2010-09-22   \n",
       "4     Trailer Park Boys: Season 2                 Yes   2010-09-22   \n",
       "5     Trailer Park Boys: Season 4                 Yes   2010-09-22   \n",
       "6     Trailer Park Boys: Season 3                 Yes   2010-09-22   \n",
       "7     Trailer Park Boys: Season 5                 Yes   2010-09-22   \n",
       "8     Trailer Park Boys: Season 7                 Yes   2011-03-01   \n",
       "9     Trailer Park Boys: Season 6                 Yes   2011-03-01   \n",
       "\n",
       "  Hours Viewed  megahours_viewed  age_days  \n",
       "0   17,600,000              17.6    4839.0  \n",
       "1    7,000,000               7.0    4839.0  \n",
       "2   11,300,000              11.3    4839.0  \n",
       "3    5,400,000               5.4    4665.0  \n",
       "4    5,800,000               5.8    4665.0  \n",
       "5    6,800,000               6.8    4665.0  \n",
       "6    6,800,000               6.8    4665.0  \n",
       "7    8,400,000               8.4    4665.0  \n",
       "8    7,500,000               7.5    4505.0  \n",
       "9    4,800,000               4.8    4505.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Available Globally?</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Hours Viewed</th>\n",
       "      <th>megahours_viewed</th>\n",
       "      <th>age_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18204</th>\n",
       "      <td>Špindl</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18205</th>\n",
       "      <td>Żyć nie umierać</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18206</th>\n",
       "      <td>الناموس: Season 1</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18207</th>\n",
       "      <td>حكايات بنات الجزء ١: Season 2</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18208</th>\n",
       "      <td>حكايات بنات الجزء ١: Season 3</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18209</th>\n",
       "      <td>راس السنة</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18210</th>\n",
       "      <td>心が叫びたがってるんだ。</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18211</th>\n",
       "      <td>두근두근 내 인생</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18212</th>\n",
       "      <td>라디오 스타</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18213</th>\n",
       "      <td>선생 김봉두</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title Available Globally? Release Date   \n",
       "18204                         Špindl                  No          NaN  \\\n",
       "18205                Żyć nie umierać                  No          NaN   \n",
       "18206              الناموس: Season 1                  No          NaN   \n",
       "18207  حكايات بنات الجزء ١: Season 2                  No          NaN   \n",
       "18208  حكايات بنات الجزء ١: Season 3                  No          NaN   \n",
       "18209                      راس السنة                  No          NaN   \n",
       "18210                   心が叫びたがってるんだ。                  No          NaN   \n",
       "18211                      두근두근 내 인생                  No          NaN   \n",
       "18212                         라디오 스타                  No          NaN   \n",
       "18213                         선생 김봉두                  No          NaN   \n",
       "\n",
       "      Hours Viewed  megahours_viewed  age_days  \n",
       "18204      100,000               0.1       NaN  \n",
       "18205      100,000               0.1       NaN  \n",
       "18206      100,000               0.1       NaN  \n",
       "18207      100,000               0.1       NaN  \n",
       "18208      100,000               0.1       NaN  \n",
       "18209      100,000               0.1       NaN  \n",
       "18210      100,000               0.1       NaN  \n",
       "18211      100,000               0.1       NaN  \n",
       "18212      100,000               0.1       NaN  \n",
       "18213      100,000               0.1       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "netflix_df['age_days'] = netflix_df['Release Date'].apply(calc_age)\n",
    "\n",
    "display(netflix_df.head(10))\n",
    "display(netflix_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `apply` example 3\n",
    "\n",
    "Many of the titles appear to be series, or what old people like me call \"TV shows\".  We may wish to know how many different \"properties\" there are in this dataset.  *I.e.*, a movie like *Lost in Translation* is a single artistic entity, whereas *Trailer Park Boys: Season 6* is simply another installment in an artistic entity.  \n",
    "\n",
    "Let's write a function that grabs all of the stuff before the colon (\":\") in a title an puts it in a new column called `property`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Available Globally?</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Hours Viewed</th>\n",
       "      <th>megahours_viewed</th>\n",
       "      <th>age_days</th>\n",
       "      <th>property</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arrested Development: Season 1</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>17,600,000</td>\n",
       "      <td>17.6</td>\n",
       "      <td>4839.0</td>\n",
       "      <td>Arrested Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arrested Development: Season 3</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>7,000,000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4839.0</td>\n",
       "      <td>Arrested Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arrested Development: Season 2</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>11,300,000</td>\n",
       "      <td>11.3</td>\n",
       "      <td>4839.0</td>\n",
       "      <td>Arrested Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trailer Park Boys: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>5,400,000</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4665.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trailer Park Boys: Season 2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>5,800,000</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4665.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trailer Park Boys: Season 4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>6,800,000</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4665.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Trailer Park Boys: Season 3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>6,800,000</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4665.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Trailer Park Boys: Season 5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>8,400,000</td>\n",
       "      <td>8.4</td>\n",
       "      <td>4665.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Trailer Park Boys: Season 7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>7,500,000</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4505.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trailer Park Boys: Season 6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>4,800,000</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4505.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title Available Globally? Release Date   \n",
       "0  Arrested Development: Season 1                  No   2010-04-01  \\\n",
       "1  Arrested Development: Season 3                  No   2010-04-01   \n",
       "2  Arrested Development: Season 2                  No   2010-04-01   \n",
       "3     Trailer Park Boys: Season 1                 Yes   2010-09-22   \n",
       "4     Trailer Park Boys: Season 2                 Yes   2010-09-22   \n",
       "5     Trailer Park Boys: Season 4                 Yes   2010-09-22   \n",
       "6     Trailer Park Boys: Season 3                 Yes   2010-09-22   \n",
       "7     Trailer Park Boys: Season 5                 Yes   2010-09-22   \n",
       "8     Trailer Park Boys: Season 7                 Yes   2011-03-01   \n",
       "9     Trailer Park Boys: Season 6                 Yes   2011-03-01   \n",
       "\n",
       "  Hours Viewed  megahours_viewed  age_days              property  \n",
       "0   17,600,000              17.6    4839.0  Arrested Development  \n",
       "1    7,000,000               7.0    4839.0  Arrested Development  \n",
       "2   11,300,000              11.3    4839.0  Arrested Development  \n",
       "3    5,400,000               5.4    4665.0     Trailer Park Boys  \n",
       "4    5,800,000               5.8    4665.0     Trailer Park Boys  \n",
       "5    6,800,000               6.8    4665.0     Trailer Park Boys  \n",
       "6    6,800,000               6.8    4665.0     Trailer Park Boys  \n",
       "7    8,400,000               8.4    4665.0     Trailer Park Boys  \n",
       "8    7,500,000               7.5    4505.0     Trailer Park Boys  \n",
       "9    4,800,000               4.8    4505.0     Trailer Park Boys  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def property(t):\n",
    "    prop = t.split(\":\")[0]\n",
    "    return prop\n",
    "\n",
    "netflix_df['property'] = netflix_df['Title'].apply(property)\n",
    "\n",
    "display(netflix_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it worked well enough!  Whether we can reliably interpret this new column is something that we'll need to investigate later on.  For example, I'm not sure what to make of \"Kevin Hart: What Now?\"\n",
    "\n",
    "#### Warm-up problem (must do this!)\n",
    "\n",
    "Below is a function that determines whether 'Season' or 'Series' appears in a string.  Write some code that applies this function to the titles in the dataframe to produce a new column called 'series?'.  Later we'll use this to approximate whether each title is more like a TV show or a movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season_in_title(t):\n",
    "    if 'Season' in t or 'Series' in t:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Available Globally?</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Hours Viewed</th>\n",
       "      <th>megahours_viewed</th>\n",
       "      <th>age_days</th>\n",
       "      <th>property</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arrested Development: Season 1</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>17,600,000</td>\n",
       "      <td>17.6</td>\n",
       "      <td>4839.0</td>\n",
       "      <td>Arrested Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arrested Development: Season 3</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>7,000,000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4839.0</td>\n",
       "      <td>Arrested Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arrested Development: Season 2</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>11,300,000</td>\n",
       "      <td>11.3</td>\n",
       "      <td>4839.0</td>\n",
       "      <td>Arrested Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trailer Park Boys: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>5,400,000</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4665.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trailer Park Boys: Season 2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>5,800,000</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4665.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trailer Park Boys: Season 4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>6,800,000</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4665.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Trailer Park Boys: Season 3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>6,800,000</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4665.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Trailer Park Boys: Season 5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>8,400,000</td>\n",
       "      <td>8.4</td>\n",
       "      <td>4665.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Trailer Park Boys: Season 7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>7,500,000</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4505.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trailer Park Boys: Season 6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>4,800,000</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4505.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>La Reina del Sur: Season 1</td>\n",
       "      <td>No</td>\n",
       "      <td>2011-09-05</td>\n",
       "      <td>94,700,000</td>\n",
       "      <td>94.7</td>\n",
       "      <td>4317.0</td>\n",
       "      <td>La Reina del Sur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lilyhammer: Season 1</td>\n",
       "      <td>No</td>\n",
       "      <td>2012-02-06</td>\n",
       "      <td>3,500,000</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4163.0</td>\n",
       "      <td>Lilyhammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>House of Cards: Season 1</td>\n",
       "      <td>No</td>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>20,000,000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3802.0</td>\n",
       "      <td>House of Cards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Black Mirror: Season 1</td>\n",
       "      <td>No</td>\n",
       "      <td>2013-02-28</td>\n",
       "      <td>20,100,000</td>\n",
       "      <td>20.1</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>Black Mirror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Longmire: Season 1</td>\n",
       "      <td>No</td>\n",
       "      <td>2013-05-15</td>\n",
       "      <td>9,600,000</td>\n",
       "      <td>9.6</td>\n",
       "      <td>3699.0</td>\n",
       "      <td>Longmire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Fall: Season 1</td>\n",
       "      <td>No</td>\n",
       "      <td>2013-05-27</td>\n",
       "      <td>6,600,000</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>The Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Orange Is the New Black: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2013-07-11</td>\n",
       "      <td>48,800,000</td>\n",
       "      <td>48.8</td>\n",
       "      <td>3642.0</td>\n",
       "      <td>Orange Is the New Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mako Mermaids: An H2O Adventure: Season 1</td>\n",
       "      <td>No</td>\n",
       "      <td>2013-07-26</td>\n",
       "      <td>24,700,000</td>\n",
       "      <td>24.7</td>\n",
       "      <td>3627.0</td>\n",
       "      <td>Mako Mermaids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rita: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2,400,000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3608.0</td>\n",
       "      <td>Rita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Derek: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2013-09-12</td>\n",
       "      <td>900,000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3579.0</td>\n",
       "      <td>Derek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Title Available Globally?   \n",
       "0              Arrested Development: Season 1                  No  \\\n",
       "1              Arrested Development: Season 3                  No   \n",
       "2              Arrested Development: Season 2                  No   \n",
       "3                 Trailer Park Boys: Season 1                 Yes   \n",
       "4                 Trailer Park Boys: Season 2                 Yes   \n",
       "5                 Trailer Park Boys: Season 4                 Yes   \n",
       "6                 Trailer Park Boys: Season 3                 Yes   \n",
       "7                 Trailer Park Boys: Season 5                 Yes   \n",
       "8                 Trailer Park Boys: Season 7                 Yes   \n",
       "9                 Trailer Park Boys: Season 6                 Yes   \n",
       "10                 La Reina del Sur: Season 1                  No   \n",
       "11                       Lilyhammer: Season 1                  No   \n",
       "12                   House of Cards: Season 1                  No   \n",
       "13                     Black Mirror: Season 1                  No   \n",
       "14                         Longmire: Season 1                  No   \n",
       "15                         The Fall: Season 1                  No   \n",
       "16          Orange Is the New Black: Season 1                 Yes   \n",
       "17  Mako Mermaids: An H2O Adventure: Season 1                  No   \n",
       "18                             Rita: Season 1                 Yes   \n",
       "19                            Derek: Season 1                 Yes   \n",
       "\n",
       "   Release Date Hours Viewed  megahours_viewed  age_days   \n",
       "0    2010-04-01   17,600,000              17.6    4839.0  \\\n",
       "1    2010-04-01    7,000,000               7.0    4839.0   \n",
       "2    2010-04-01   11,300,000              11.3    4839.0   \n",
       "3    2010-09-22    5,400,000               5.4    4665.0   \n",
       "4    2010-09-22    5,800,000               5.8    4665.0   \n",
       "5    2010-09-22    6,800,000               6.8    4665.0   \n",
       "6    2010-09-22    6,800,000               6.8    4665.0   \n",
       "7    2010-09-22    8,400,000               8.4    4665.0   \n",
       "8    2011-03-01    7,500,000               7.5    4505.0   \n",
       "9    2011-03-01    4,800,000               4.8    4505.0   \n",
       "10   2011-09-05   94,700,000              94.7    4317.0   \n",
       "11   2012-02-06    3,500,000               3.5    4163.0   \n",
       "12   2013-02-01   20,000,000              20.0    3802.0   \n",
       "13   2013-02-28   20,100,000              20.1    3775.0   \n",
       "14   2013-05-15    9,600,000               9.6    3699.0   \n",
       "15   2013-05-27    6,600,000               6.6    3687.0   \n",
       "16   2013-07-11   48,800,000              48.8    3642.0   \n",
       "17   2013-07-26   24,700,000              24.7    3627.0   \n",
       "18   2013-08-14    2,400,000               2.4    3608.0   \n",
       "19   2013-09-12      900,000               0.9    3579.0   \n",
       "\n",
       "                   property  \n",
       "0      Arrested Development  \n",
       "1      Arrested Development  \n",
       "2      Arrested Development  \n",
       "3         Trailer Park Boys  \n",
       "4         Trailer Park Boys  \n",
       "5         Trailer Park Boys  \n",
       "6         Trailer Park Boys  \n",
       "7         Trailer Park Boys  \n",
       "8         Trailer Park Boys  \n",
       "9         Trailer Park Boys  \n",
       "10         La Reina del Sur  \n",
       "11               Lilyhammer  \n",
       "12           House of Cards  \n",
       "13             Black Mirror  \n",
       "14                 Longmire  \n",
       "15                 The Fall  \n",
       "16  Orange Is the New Black  \n",
       "17            Mako Mermaids  \n",
       "18                     Rita  \n",
       "19                    Derek  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### your code goes here\n",
    "\n",
    "\n",
    "\n",
    "display(netflix_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warm-up problem\n",
    "\n",
    "Below is a function that counts the number of non-Roman characters in a string.  Write some code that applies this function to the titles in the dataframe to produce a new column called 'non_roman_characters'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "roman_chars = list('abcdcefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ 1234567890!.,;:?')\n",
    "def get_non_roman_chars(s):\n",
    "    non_roman_chars = 0\n",
    "    s_arr = list(s)\n",
    "    for c in s_arr:\n",
    "        if c not in roman_chars:\n",
    "            non_roman_chars += 1\n",
    "    return non_roman_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Available Globally?</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Hours Viewed</th>\n",
       "      <th>megahours_viewed</th>\n",
       "      <th>age_days</th>\n",
       "      <th>property</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arrested Development: Season 1</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>17,600,000</td>\n",
       "      <td>17.6</td>\n",
       "      <td>4839.0</td>\n",
       "      <td>Arrested Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arrested Development: Season 3</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>7,000,000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4839.0</td>\n",
       "      <td>Arrested Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arrested Development: Season 2</td>\n",
       "      <td>No</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>11,300,000</td>\n",
       "      <td>11.3</td>\n",
       "      <td>4839.0</td>\n",
       "      <td>Arrested Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trailer Park Boys: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>5,400,000</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4665.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trailer Park Boys: Season 2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>5,800,000</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4665.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trailer Park Boys: Season 4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>6,800,000</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4665.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Trailer Park Boys: Season 3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>6,800,000</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4665.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Trailer Park Boys: Season 5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>8,400,000</td>\n",
       "      <td>8.4</td>\n",
       "      <td>4665.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Trailer Park Boys: Season 7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>7,500,000</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4505.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trailer Park Boys: Season 6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>4,800,000</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4505.0</td>\n",
       "      <td>Trailer Park Boys</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title Available Globally? Release Date   \n",
       "0  Arrested Development: Season 1                  No   2010-04-01  \\\n",
       "1  Arrested Development: Season 3                  No   2010-04-01   \n",
       "2  Arrested Development: Season 2                  No   2010-04-01   \n",
       "3     Trailer Park Boys: Season 1                 Yes   2010-09-22   \n",
       "4     Trailer Park Boys: Season 2                 Yes   2010-09-22   \n",
       "5     Trailer Park Boys: Season 4                 Yes   2010-09-22   \n",
       "6     Trailer Park Boys: Season 3                 Yes   2010-09-22   \n",
       "7     Trailer Park Boys: Season 5                 Yes   2010-09-22   \n",
       "8     Trailer Park Boys: Season 7                 Yes   2011-03-01   \n",
       "9     Trailer Park Boys: Season 6                 Yes   2011-03-01   \n",
       "\n",
       "  Hours Viewed  megahours_viewed  age_days              property  \n",
       "0   17,600,000              17.6    4839.0  Arrested Development  \n",
       "1    7,000,000               7.0    4839.0  Arrested Development  \n",
       "2   11,300,000              11.3    4839.0  Arrested Development  \n",
       "3    5,400,000               5.4    4665.0     Trailer Park Boys  \n",
       "4    5,800,000               5.8    4665.0     Trailer Park Boys  \n",
       "5    6,800,000               6.8    4665.0     Trailer Park Boys  \n",
       "6    6,800,000               6.8    4665.0     Trailer Park Boys  \n",
       "7    8,400,000               8.4    4665.0     Trailer Park Boys  \n",
       "8    7,500,000               7.5    4505.0     Trailer Park Boys  \n",
       "9    4,800,000               4.8    4505.0     Trailer Park Boys  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Available Globally?</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Hours Viewed</th>\n",
       "      <th>megahours_viewed</th>\n",
       "      <th>age_days</th>\n",
       "      <th>property</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18204</th>\n",
       "      <td>Špindl</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Špindl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18205</th>\n",
       "      <td>Żyć nie umierać</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Żyć nie umierać</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18206</th>\n",
       "      <td>الناموس: Season 1</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>الناموس</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18207</th>\n",
       "      <td>حكايات بنات الجزء ١: Season 2</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>حكايات بنات الجزء ١</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18208</th>\n",
       "      <td>حكايات بنات الجزء ١: Season 3</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>حكايات بنات الجزء ١</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18209</th>\n",
       "      <td>راس السنة</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>راس السنة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18210</th>\n",
       "      <td>心が叫びたがってるんだ。</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>心が叫びたがってるんだ。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18211</th>\n",
       "      <td>두근두근 내 인생</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>두근두근 내 인생</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18212</th>\n",
       "      <td>라디오 스타</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>라디오 스타</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18213</th>\n",
       "      <td>선생 김봉두</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>선생 김봉두</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title Available Globally? Release Date   \n",
       "18204                         Špindl                  No          NaN  \\\n",
       "18205                Żyć nie umierać                  No          NaN   \n",
       "18206              الناموس: Season 1                  No          NaN   \n",
       "18207  حكايات بنات الجزء ١: Season 2                  No          NaN   \n",
       "18208  حكايات بنات الجزء ١: Season 3                  No          NaN   \n",
       "18209                      راس السنة                  No          NaN   \n",
       "18210                   心が叫びたがってるんだ。                  No          NaN   \n",
       "18211                      두근두근 내 인생                  No          NaN   \n",
       "18212                         라디오 스타                  No          NaN   \n",
       "18213                         선생 김봉두                  No          NaN   \n",
       "\n",
       "      Hours Viewed  megahours_viewed  age_days             property  \n",
       "18204      100,000               0.1       NaN               Špindl  \n",
       "18205      100,000               0.1       NaN      Żyć nie umierać  \n",
       "18206      100,000               0.1       NaN              الناموس  \n",
       "18207      100,000               0.1       NaN  حكايات بنات الجزء ١  \n",
       "18208      100,000               0.1       NaN  حكايات بنات الجزء ١  \n",
       "18209      100,000               0.1       NaN            راس السنة  \n",
       "18210      100,000               0.1       NaN         心が叫びたがってるんだ。  \n",
       "18211      100,000               0.1       NaN            두근두근 내 인생  \n",
       "18212      100,000               0.1       NaN               라디오 스타  \n",
       "18213      100,000               0.1       NaN               선생 김봉두  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### your code goes here\n",
    "\n",
    "\n",
    "display(netflix_df.head(10))\n",
    "display(netflix_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warm-up problem\n",
    "\n",
    "Now you try!  Write a function, `bool_convert`, that takes a string as input and produces a 0 if the string is 'No' and a 1 if the string is 'Yes'.  Apply this function to the \"Available Globally?\" column of the dataframe to produce a new column called \"avail_globally_int\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Re-ordering the dataset --> `sort_values`\n",
    "\n",
    "So far we've been taking glances at the dataframe by using the `head` and `tail` functions.  But the dataframe is ordered based on titles' release dates, which isn't super helpful for many of the research questions we established above.  \n",
    "\n",
    "The `Dataframe.sort_values` function can re-order the dataframe according to any column(s) that we provide.  For example, we can answer our first research question by doing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Available Globally?</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Hours Viewed</th>\n",
       "      <th>megahours_viewed</th>\n",
       "      <th>age_days</th>\n",
       "      <th>property</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18213</th>\n",
       "      <td>선생 김봉두</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>선생 김봉두</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>Phil Wang: Philly Philly Wang Wang</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2021-08-10</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>690.0</td>\n",
       "      <td>Phil Wang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16133</th>\n",
       "      <td>Kamen Rider Zero-One // 仮面ライダーゼロワン</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kamen Rider Zero-One // 仮面ライダーゼロワン</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16132</th>\n",
       "      <td>Kamen Rider Reiwa: The First Generation // 仮面ラ...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kamen Rider Reiwa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16131</th>\n",
       "      <td>Kamen Rider Heisei Generations Forever // 平成仮面...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kamen Rider Heisei Generations Forever // 平成仮面...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16130</th>\n",
       "      <td>Kameleon 2</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kameleon 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16129</th>\n",
       "      <td>Kamalatho Naa Prayanam</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kamalatho Naa Prayanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16128</th>\n",
       "      <td>Kalel, 15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kalel, 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16127</th>\n",
       "      <td>Kain Kafan Hitam</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kain Kafan Hitam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16126</th>\n",
       "      <td>Kaguya-sama: Love Is War (2019 Live Action) //...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaguya-sama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title Available Globally?   \n",
       "18213                                             선생 김봉두                  No  \\\n",
       "3189                  Phil Wang: Philly Philly Wang Wang                 Yes   \n",
       "16133                 Kamen Rider Zero-One // 仮面ライダーゼロワン                  No   \n",
       "16132  Kamen Rider Reiwa: The First Generation // 仮面ラ...                  No   \n",
       "16131  Kamen Rider Heisei Generations Forever // 平成仮面...                  No   \n",
       "16130                                         Kameleon 2                  No   \n",
       "16129                             Kamalatho Naa Prayanam                  No   \n",
       "16128                                          Kalel, 15                 Yes   \n",
       "16127                                   Kain Kafan Hitam                  No   \n",
       "16126  Kaguya-sama: Love Is War (2019 Live Action) //...                  No   \n",
       "\n",
       "      Release Date Hours Viewed  megahours_viewed  age_days   \n",
       "18213          NaN      100,000               0.1       NaN  \\\n",
       "3189    2021-08-10      100,000               0.1     690.0   \n",
       "16133          NaN      100,000               0.1       NaN   \n",
       "16132          NaN      100,000               0.1       NaN   \n",
       "16131          NaN      100,000               0.1       NaN   \n",
       "16130          NaN      100,000               0.1       NaN   \n",
       "16129          NaN      100,000               0.1       NaN   \n",
       "16128          NaN      100,000               0.1       NaN   \n",
       "16127          NaN      100,000               0.1       NaN   \n",
       "16126          NaN      100,000               0.1       NaN   \n",
       "\n",
       "                                                property  \n",
       "18213                                             선생 김봉두  \n",
       "3189                                           Phil Wang  \n",
       "16133                 Kamen Rider Zero-One // 仮面ライダーゼロワン  \n",
       "16132                                  Kamen Rider Reiwa  \n",
       "16131  Kamen Rider Heisei Generations Forever // 平成仮面...  \n",
       "16130                                         Kameleon 2  \n",
       "16129                             Kamalatho Naa Prayanam  \n",
       "16128                                          Kalel, 15  \n",
       "16127                                   Kain Kafan Hitam  \n",
       "16126                                        Kaguya-sama  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "netflix_df = netflix_df.sort_values('megahours_viewed')\n",
    "\n",
    "display(netflix_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that it looks like `pandas` defaults to ascending order; it put the least-viewed titles at the top of the dataframe.  We can reverse this by setting the `ascending` keyword to `False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Available Globally?</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Hours Viewed</th>\n",
       "      <th>megahours_viewed</th>\n",
       "      <th>age_days</th>\n",
       "      <th>property</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4670</th>\n",
       "      <td>The Night Agent: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-03-23</td>\n",
       "      <td>812,100,000</td>\n",
       "      <td>812.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>The Night Agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532</th>\n",
       "      <td>Ginny &amp; Georgia: Season 2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>665,100,000</td>\n",
       "      <td>665.1</td>\n",
       "      <td>177.0</td>\n",
       "      <td>Ginny &amp; Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4517</th>\n",
       "      <td>The Glory: Season 1 // 더 글로리: 시즌 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>622,800,000</td>\n",
       "      <td>622.8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>The Glory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>Wednesday: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2022-11-23</td>\n",
       "      <td>507,700,000</td>\n",
       "      <td>507.7</td>\n",
       "      <td>220.0</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4754</th>\n",
       "      <td>Queen Charlotte: A Bridgerton Story</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-05-04</td>\n",
       "      <td>503,000,000</td>\n",
       "      <td>503.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Queen Charlotte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4591</th>\n",
       "      <td>You: Season 4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-02-09</td>\n",
       "      <td>440,600,000</td>\n",
       "      <td>440.6</td>\n",
       "      <td>142.0</td>\n",
       "      <td>You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>La Reina del Sur: Season 3</td>\n",
       "      <td>No</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>429,600,000</td>\n",
       "      <td>429.6</td>\n",
       "      <td>183.0</td>\n",
       "      <td>La Reina del Sur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4624</th>\n",
       "      <td>Outer Banks: Season 3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-02-23</td>\n",
       "      <td>402,500,000</td>\n",
       "      <td>402.5</td>\n",
       "      <td>128.0</td>\n",
       "      <td>Outer Banks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>Ginny &amp; Georgia: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>302,100,000</td>\n",
       "      <td>302.1</td>\n",
       "      <td>857.0</td>\n",
       "      <td>Ginny &amp; Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>FUBAR: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-05-25</td>\n",
       "      <td>266,200,000</td>\n",
       "      <td>266.2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>FUBAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4349</th>\n",
       "      <td>Manifest: Season 4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2022-11-04</td>\n",
       "      <td>262,600,000</td>\n",
       "      <td>262.6</td>\n",
       "      <td>239.0</td>\n",
       "      <td>Manifest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4527</th>\n",
       "      <td>Kaleidoscope: Limited Series</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>252,500,000</td>\n",
       "      <td>252.5</td>\n",
       "      <td>181.0</td>\n",
       "      <td>Kaleidoscope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>Firefly Lane: Season 2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>251,500,000</td>\n",
       "      <td>251.5</td>\n",
       "      <td>211.0</td>\n",
       "      <td>Firefly Lane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4764</th>\n",
       "      <td>The Mother</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>249,900,000</td>\n",
       "      <td>249.9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>The Mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4566</th>\n",
       "      <td>Physical: 100: Season 1 // 피지컬: 100: 시즌 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>235,000,000</td>\n",
       "      <td>235.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>Physical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>Crash Course in Romance: Limited Series // 일타 ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>234,800,000</td>\n",
       "      <td>234.8</td>\n",
       "      <td>168.0</td>\n",
       "      <td>Crash Course in Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>Love Is Blind: Season 4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-03-24</td>\n",
       "      <td>229,700,000</td>\n",
       "      <td>229.7</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Love Is Blind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692</th>\n",
       "      <td>BEEF: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>221,100,000</td>\n",
       "      <td>221.1</td>\n",
       "      <td>86.0</td>\n",
       "      <td>BEEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4725</th>\n",
       "      <td>The Diplomat: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-04-20</td>\n",
       "      <td>214,100,000</td>\n",
       "      <td>214.1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>The Diplomat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4649</th>\n",
       "      <td>Luther: The Fallen Sun</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-03-10</td>\n",
       "      <td>209,700,000</td>\n",
       "      <td>209.7</td>\n",
       "      <td>113.0</td>\n",
       "      <td>Luther</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title Available Globally?   \n",
       "4670                          The Night Agent: Season 1                 Yes  \\\n",
       "4532                          Ginny & Georgia: Season 2                 Yes   \n",
       "4517                 The Glory: Season 1 // 더 글로리: 시즌 1                 Yes   \n",
       "4405                                Wednesday: Season 1                 Yes   \n",
       "4754                Queen Charlotte: A Bridgerton Story                 Yes   \n",
       "4591                                      You: Season 4                 Yes   \n",
       "4519                         La Reina del Sur: Season 3                  No   \n",
       "4624                              Outer Banks: Season 3                 Yes   \n",
       "2856                          Ginny & Georgia: Season 1                 Yes   \n",
       "4788                                    FUBAR: Season 1                 Yes   \n",
       "4349                                 Manifest: Season 4                 Yes   \n",
       "4527                       Kaleidoscope: Limited Series                 Yes   \n",
       "4438                             Firefly Lane: Season 2                 Yes   \n",
       "4764                                         The Mother                 Yes   \n",
       "4566          Physical: 100: Season 1 // 피지컬: 100: 시즌 1                 Yes   \n",
       "4549  Crash Course in Romance: Limited Series // 일타 ...                 Yes   \n",
       "4676                            Love Is Blind: Season 4                 Yes   \n",
       "4692                                     BEEF: Season 1                 Yes   \n",
       "4725                             The Diplomat: Season 1                 Yes   \n",
       "4649                             Luther: The Fallen Sun                 Yes   \n",
       "\n",
       "     Release Date Hours Viewed  megahours_viewed  age_days   \n",
       "4670   2023-03-23  812,100,000             812.1     100.0  \\\n",
       "4532   2023-01-05  665,100,000             665.1     177.0   \n",
       "4517   2022-12-30  622,800,000             622.8     183.0   \n",
       "4405   2022-11-23  507,700,000             507.7     220.0   \n",
       "4754   2023-05-04  503,000,000             503.0      58.0   \n",
       "4591   2023-02-09  440,600,000             440.6     142.0   \n",
       "4519   2022-12-30  429,600,000             429.6     183.0   \n",
       "4624   2023-02-23  402,500,000             402.5     128.0   \n",
       "2856   2021-02-24  302,100,000             302.1     857.0   \n",
       "4788   2023-05-25  266,200,000             266.2      37.0   \n",
       "4349   2022-11-04  262,600,000             262.6     239.0   \n",
       "4527   2023-01-01  252,500,000             252.5     181.0   \n",
       "4438   2022-12-02  251,500,000             251.5     211.0   \n",
       "4764   2023-05-12  249,900,000             249.9      50.0   \n",
       "4566   2023-01-24  235,000,000             235.0     158.0   \n",
       "4549   2023-01-14  234,800,000             234.8     168.0   \n",
       "4676   2023-03-24  229,700,000             229.7      99.0   \n",
       "4692   2023-04-06  221,100,000             221.1      86.0   \n",
       "4725   2023-04-20  214,100,000             214.1      72.0   \n",
       "4649   2023-03-10  209,700,000             209.7     113.0   \n",
       "\n",
       "                     property  \n",
       "4670          The Night Agent  \n",
       "4532          Ginny & Georgia  \n",
       "4517                The Glory  \n",
       "4405                Wednesday  \n",
       "4754          Queen Charlotte  \n",
       "4591                      You  \n",
       "4519         La Reina del Sur  \n",
       "4624              Outer Banks  \n",
       "2856          Ginny & Georgia  \n",
       "4788                    FUBAR  \n",
       "4349                 Manifest  \n",
       "4527             Kaleidoscope  \n",
       "4438             Firefly Lane  \n",
       "4764               The Mother  \n",
       "4566                 Physical  \n",
       "4549  Crash Course in Romance  \n",
       "4676            Love Is Blind  \n",
       "4692                     BEEF  \n",
       "4725             The Diplomat  \n",
       "4649                   Luther  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "netflix_df = netflix_df.sort_values('megahours_viewed', ascending=False)\n",
    "\n",
    "display(netflix_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there's the answer to our first question!  *The Night Agent* (which I am just now learning is a thing that exists) was the most-viewed show during this period.\n",
    "\n",
    "Notice that the index column on the left still shows the original indices of the rows in the dataframe.  If we're confident that we'd like to keep this new ordering of the dataframe, we can reset the indices thusly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Available Globally?</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Hours Viewed</th>\n",
       "      <th>megahours_viewed</th>\n",
       "      <th>age_days</th>\n",
       "      <th>property</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Night Agent: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-03-23</td>\n",
       "      <td>812,100,000</td>\n",
       "      <td>812.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>The Night Agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ginny &amp; Georgia: Season 2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>665,100,000</td>\n",
       "      <td>665.1</td>\n",
       "      <td>177.0</td>\n",
       "      <td>Ginny &amp; Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Glory: Season 1 // 더 글로리: 시즌 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>622,800,000</td>\n",
       "      <td>622.8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>The Glory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wednesday: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2022-11-23</td>\n",
       "      <td>507,700,000</td>\n",
       "      <td>507.7</td>\n",
       "      <td>220.0</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Queen Charlotte: A Bridgerton Story</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-05-04</td>\n",
       "      <td>503,000,000</td>\n",
       "      <td>503.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Queen Charlotte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>You: Season 4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-02-09</td>\n",
       "      <td>440,600,000</td>\n",
       "      <td>440.6</td>\n",
       "      <td>142.0</td>\n",
       "      <td>You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>La Reina del Sur: Season 3</td>\n",
       "      <td>No</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>429,600,000</td>\n",
       "      <td>429.6</td>\n",
       "      <td>183.0</td>\n",
       "      <td>La Reina del Sur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Outer Banks: Season 3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-02-23</td>\n",
       "      <td>402,500,000</td>\n",
       "      <td>402.5</td>\n",
       "      <td>128.0</td>\n",
       "      <td>Outer Banks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ginny &amp; Georgia: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>302,100,000</td>\n",
       "      <td>302.1</td>\n",
       "      <td>857.0</td>\n",
       "      <td>Ginny &amp; Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FUBAR: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-05-25</td>\n",
       "      <td>266,200,000</td>\n",
       "      <td>266.2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>FUBAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manifest: Season 4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2022-11-04</td>\n",
       "      <td>262,600,000</td>\n",
       "      <td>262.6</td>\n",
       "      <td>239.0</td>\n",
       "      <td>Manifest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kaleidoscope: Limited Series</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>252,500,000</td>\n",
       "      <td>252.5</td>\n",
       "      <td>181.0</td>\n",
       "      <td>Kaleidoscope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Firefly Lane: Season 2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>251,500,000</td>\n",
       "      <td>251.5</td>\n",
       "      <td>211.0</td>\n",
       "      <td>Firefly Lane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Mother</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>249,900,000</td>\n",
       "      <td>249.9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>The Mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Physical: 100: Season 1 // 피지컬: 100: 시즌 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>235,000,000</td>\n",
       "      <td>235.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>Physical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Crash Course in Romance: Limited Series // 일타 ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>234,800,000</td>\n",
       "      <td>234.8</td>\n",
       "      <td>168.0</td>\n",
       "      <td>Crash Course in Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Love Is Blind: Season 4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-03-24</td>\n",
       "      <td>229,700,000</td>\n",
       "      <td>229.7</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Love Is Blind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BEEF: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>221,100,000</td>\n",
       "      <td>221.1</td>\n",
       "      <td>86.0</td>\n",
       "      <td>BEEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Diplomat: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-04-20</td>\n",
       "      <td>214,100,000</td>\n",
       "      <td>214.1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>The Diplomat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Luther: The Fallen Sun</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-03-10</td>\n",
       "      <td>209,700,000</td>\n",
       "      <td>209.7</td>\n",
       "      <td>113.0</td>\n",
       "      <td>Luther</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title Available Globally?   \n",
       "0                           The Night Agent: Season 1                 Yes  \\\n",
       "1                           Ginny & Georgia: Season 2                 Yes   \n",
       "2                  The Glory: Season 1 // 더 글로리: 시즌 1                 Yes   \n",
       "3                                 Wednesday: Season 1                 Yes   \n",
       "4                 Queen Charlotte: A Bridgerton Story                 Yes   \n",
       "5                                       You: Season 4                 Yes   \n",
       "6                          La Reina del Sur: Season 3                  No   \n",
       "7                               Outer Banks: Season 3                 Yes   \n",
       "8                           Ginny & Georgia: Season 1                 Yes   \n",
       "9                                     FUBAR: Season 1                 Yes   \n",
       "10                                 Manifest: Season 4                 Yes   \n",
       "11                       Kaleidoscope: Limited Series                 Yes   \n",
       "12                             Firefly Lane: Season 2                 Yes   \n",
       "13                                         The Mother                 Yes   \n",
       "14          Physical: 100: Season 1 // 피지컬: 100: 시즌 1                 Yes   \n",
       "15  Crash Course in Romance: Limited Series // 일타 ...                 Yes   \n",
       "16                            Love Is Blind: Season 4                 Yes   \n",
       "17                                     BEEF: Season 1                 Yes   \n",
       "18                             The Diplomat: Season 1                 Yes   \n",
       "19                             Luther: The Fallen Sun                 Yes   \n",
       "\n",
       "   Release Date Hours Viewed  megahours_viewed  age_days   \n",
       "0    2023-03-23  812,100,000             812.1     100.0  \\\n",
       "1    2023-01-05  665,100,000             665.1     177.0   \n",
       "2    2022-12-30  622,800,000             622.8     183.0   \n",
       "3    2022-11-23  507,700,000             507.7     220.0   \n",
       "4    2023-05-04  503,000,000             503.0      58.0   \n",
       "5    2023-02-09  440,600,000             440.6     142.0   \n",
       "6    2022-12-30  429,600,000             429.6     183.0   \n",
       "7    2023-02-23  402,500,000             402.5     128.0   \n",
       "8    2021-02-24  302,100,000             302.1     857.0   \n",
       "9    2023-05-25  266,200,000             266.2      37.0   \n",
       "10   2022-11-04  262,600,000             262.6     239.0   \n",
       "11   2023-01-01  252,500,000             252.5     181.0   \n",
       "12   2022-12-02  251,500,000             251.5     211.0   \n",
       "13   2023-05-12  249,900,000             249.9      50.0   \n",
       "14   2023-01-24  235,000,000             235.0     158.0   \n",
       "15   2023-01-14  234,800,000             234.8     168.0   \n",
       "16   2023-03-24  229,700,000             229.7      99.0   \n",
       "17   2023-04-06  221,100,000             221.1      86.0   \n",
       "18   2023-04-20  214,100,000             214.1      72.0   \n",
       "19   2023-03-10  209,700,000             209.7     113.0   \n",
       "\n",
       "                   property  \n",
       "0           The Night Agent  \n",
       "1           Ginny & Georgia  \n",
       "2                 The Glory  \n",
       "3                 Wednesday  \n",
       "4           Queen Charlotte  \n",
       "5                       You  \n",
       "6          La Reina del Sur  \n",
       "7               Outer Banks  \n",
       "8           Ginny & Georgia  \n",
       "9                     FUBAR  \n",
       "10                 Manifest  \n",
       "11             Kaleidoscope  \n",
       "12             Firefly Lane  \n",
       "13               The Mother  \n",
       "14                 Physical  \n",
       "15  Crash Course in Romance  \n",
       "16            Love Is Blind  \n",
       "17                     BEEF  \n",
       "18             The Diplomat  \n",
       "19                   Luther  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "netflix_df = netflix_df.reset_index(drop=True)\n",
    "\n",
    "display(netflix_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, *The Night Agent* -- you're #0!\n",
    "\n",
    "The majority of the top-twenty titles appear to be what we could consider to be shows/series!  This is maybe not surprising.  \n",
    "\n",
    "`sort_values` also allows you to sort based on two features.  Say we want to sort based on the days since release and then by the number of hours viewed.  We supply `sort_values` with a list of column names.  I just want to show you this; I don't want to actually change the dataframe.  See if you can parse the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Available Globally?</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Hours Viewed</th>\n",
       "      <th>megahours_viewed</th>\n",
       "      <th>age_days</th>\n",
       "      <th>property</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6209</th>\n",
       "      <td>Nimona</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>1,800,000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Nimona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>Celebrity: Limited Series // 셀러브리티: 리미티드 시리즈</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>2,600,000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Celebrity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4846</th>\n",
       "      <td>Is It Cake, Too?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>3,000,000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Is It Cake, Too?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7385</th>\n",
       "      <td>Ōoku: The Inner Chambers: Season 1 // 大奥: シーズン1</td>\n",
       "      <td>No</td>\n",
       "      <td>2023-06-29</td>\n",
       "      <td>1,200,000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Ōoku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>Lust Stories 2 // लस्ट स्टोरीज़ 2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-06-29</td>\n",
       "      <td>5,200,000</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Lust Stories 2 // लस्ट स्टोरीज़ 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>The Witcher: Season 3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-06-29</td>\n",
       "      <td>33,400,000</td>\n",
       "      <td>33.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The Witcher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8246</th>\n",
       "      <td>Eldorado: Everything the Nazis Hate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-06-28</td>\n",
       "      <td>900,000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Eldorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>Muscles &amp; Mayhem: An Unauthorized Story of Ame...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-06-28</td>\n",
       "      <td>6,300,000</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Muscles &amp; Mayhem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>Run Rabbit Run</td>\n",
       "      <td>No</td>\n",
       "      <td>2023-06-28</td>\n",
       "      <td>7,300,000</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Run Rabbit Run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>DELETE: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-06-28</td>\n",
       "      <td>8,000,000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>DELETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>Titans: Season 4</td>\n",
       "      <td>No</td>\n",
       "      <td>2023-06-25</td>\n",
       "      <td>19,700,000</td>\n",
       "      <td>19.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Titans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>King of Clones // 킹 오브 클론 : 황우석 박사의 몰락</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-06-23</td>\n",
       "      <td>3,700,000</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>King of Clones // 킹 오브 클론</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3014</th>\n",
       "      <td>Pokémon Ultimate Journeys: The Series: Part 3</td>\n",
       "      <td>No</td>\n",
       "      <td>2023-06-23</td>\n",
       "      <td>6,300,000</td>\n",
       "      <td>6.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Pokémon Ultimate Journeys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>iNumber Number: Jozi Gold</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-06-23</td>\n",
       "      <td>11,700,000</td>\n",
       "      <td>11.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>iNumber Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>Catching Killers: Season 3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-06-23</td>\n",
       "      <td>19,800,000</td>\n",
       "      <td>19.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Catching Killers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>Make Me Believe // Sen İnandır</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-06-23</td>\n",
       "      <td>24,000,000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Make Me Believe // Sen İnandır</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>The Perfect Find</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-06-23</td>\n",
       "      <td>25,400,000</td>\n",
       "      <td>25.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>The Perfect Find</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Through My Window 2: Across the Sea // A travé...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-06-23</td>\n",
       "      <td>42,900,000</td>\n",
       "      <td>42.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Through My Window 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>Skull Island: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>7,400,000</td>\n",
       "      <td>7.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Skull Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>Let's Get Divorced: Season 1 // 離婚しようよ: シーズン1</td>\n",
       "      <td>No</td>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>11,700,000</td>\n",
       "      <td>11.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Let's Get Divorced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title Available Globally?   \n",
       "6209                                             Nimona                 Yes  \\\n",
       "5168       Celebrity: Limited Series // 셀러브리티: 리미티드 시리즈                 Yes   \n",
       "4846                                   Is It Cake, Too?                 Yes   \n",
       "7385    Ōoku: The Inner Chambers: Season 1 // 大奥: シーズン1                  No   \n",
       "3455                  Lust Stories 2 // लस्ट स्टोरीज़ 2                 Yes   \n",
       "547                               The Witcher: Season 3                 Yes   \n",
       "8246                Eldorado: Everything the Nazis Hate                 Yes   \n",
       "2976  Muscles & Mayhem: An Unauthorized Story of Ame...                 Yes   \n",
       "2673                                     Run Rabbit Run                  No   \n",
       "2491                                   DELETE: Season 1                 Yes   \n",
       "1084                                   Titans: Season 4                  No   \n",
       "4288             King of Clones // 킹 오브 클론 : 황우석 박사의 몰락                 Yes   \n",
       "3014      Pokémon Ultimate Journeys: The Series: Part 3                  No   \n",
       "1785                          iNumber Number: Jozi Gold                 Yes   \n",
       "1079                         Catching Killers: Season 3                 Yes   \n",
       "870                      Make Me Believe // Sen İnandır                 Yes   \n",
       "817                                    The Perfect Find                 Yes   \n",
       "375   Through My Window 2: Across the Sea // A travé...                 Yes   \n",
       "2639                             Skull Island: Season 1                 Yes   \n",
       "1778      Let's Get Divorced: Season 1 // 離婚しようよ: シーズン1                  No   \n",
       "\n",
       "     Release Date Hours Viewed  megahours_viewed  age_days   \n",
       "6209   2023-06-30    1,800,000               1.8       1.0  \\\n",
       "5168   2023-06-30    2,600,000               2.6       1.0   \n",
       "4846   2023-06-30    3,000,000               3.0       1.0   \n",
       "7385   2023-06-29    1,200,000               1.2       2.0   \n",
       "3455   2023-06-29    5,200,000               5.2       2.0   \n",
       "547    2023-06-29   33,400,000              33.4       2.0   \n",
       "8246   2023-06-28      900,000               0.9       3.0   \n",
       "2976   2023-06-28    6,300,000               6.3       3.0   \n",
       "2673   2023-06-28    7,300,000               7.3       3.0   \n",
       "2491   2023-06-28    8,000,000               8.0       3.0   \n",
       "1084   2023-06-25   19,700,000              19.7       6.0   \n",
       "4288   2023-06-23    3,700,000               3.7       8.0   \n",
       "3014   2023-06-23    6,300,000               6.3       8.0   \n",
       "1785   2023-06-23   11,700,000              11.7       8.0   \n",
       "1079   2023-06-23   19,800,000              19.8       8.0   \n",
       "870    2023-06-23   24,000,000              24.0       8.0   \n",
       "817    2023-06-23   25,400,000              25.4       8.0   \n",
       "375    2023-06-23   42,900,000              42.9       8.0   \n",
       "2639   2023-06-22    7,400,000               7.4       9.0   \n",
       "1778   2023-06-22   11,700,000              11.7       9.0   \n",
       "\n",
       "                               property  \n",
       "6209                             Nimona  \n",
       "5168                          Celebrity  \n",
       "4846                   Is It Cake, Too?  \n",
       "7385                               Ōoku  \n",
       "3455  Lust Stories 2 // लस्ट स्टोरीज़ 2  \n",
       "547                         The Witcher  \n",
       "8246                           Eldorado  \n",
       "2976                   Muscles & Mayhem  \n",
       "2673                     Run Rabbit Run  \n",
       "2491                             DELETE  \n",
       "1084                             Titans  \n",
       "4288         King of Clones // 킹 오브 클론   \n",
       "3014          Pokémon Ultimate Journeys  \n",
       "1785                     iNumber Number  \n",
       "1079                   Catching Killers  \n",
       "870      Make Me Believe // Sen İnandır  \n",
       "817                    The Perfect Find  \n",
       "375                 Through My Window 2  \n",
       "2639                       Skull Island  \n",
       "1778                 Let's Get Divorced  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(netflix_df.sort_values(['age_days', 'megahours_viewed']).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Data reduction \n",
    "\n",
    "OK, it feels like we're getting a handle on what's in this dataset.  We can now try to *reduce* it, to boil its contents down to gain some higher-level understanding.\n",
    "\n",
    "Note that we can generate summary statistics for the entire dataset using basic `pandas` functions on the individual columns.  These summary statistics reduce the data *all the way down* to a small set of values.\n",
    "\n",
    "Before you continue, please interpret the results of each of the following lines of code (*i.e.*, talk with the person sitting next to you about what each of the output values means).  You'll may have to Google the last one; that's ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "812.1\n",
      "93455.2\n",
      "0.7\n",
      "5.130954211046448\n",
      "18.71767223616126\n",
      "- - - - -\n",
      "0.25      0.2\n",
      "0.50      0.7\n",
      "0.75      3.4\n",
      "1.00    812.1\n",
      "Name: megahours_viewed, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(netflix_df['megahours_viewed'].max())\n",
    "print(netflix_df['megahours_viewed'].sum())\n",
    "print(netflix_df['megahours_viewed'].median())\n",
    "print(netflix_df['megahours_viewed'].mean())\n",
    "print(netflix_df['megahours_viewed'].std())\n",
    "print('- - - - -')\n",
    "print(netflix_df['megahours_viewed'].quantile([0.25, 0.5, 0.75, 1.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `groupby`\n",
    "\n",
    "If you're a data science exec at Neflix, a lot of your job is probably helping the company to determine what to make and market next to ~~increase viewership or subsciptions~~ investigate the human condition.  Said simply: What do the people want?  (Or what can you convince them that they want?)  The summary statistics above are not sufficient to answer this question because in calculating them, we've reduced out all of the information about any groups of titles.\n",
    "\n",
    "Luckily, the `Dataframe.groupby` function in `pandas` can  do what we want!  \n",
    "\n",
    "Let's first look at the properties that are series.  These seem to do well.  I'll create a dataset that includes only those titles that have a 1 for the `series?` feature.  Note that if you didn't complete the first warm-up problem, the cell below **will not work!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'series?'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/miniconda3/envs/snakes/lib/python3.11/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/snakes/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/snakes/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'series?'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m series_df \u001b[38;5;241m=\u001b[39m netflix_df[netflix_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseries?\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      2\u001b[0m display(series_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/snakes/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/snakes/lib/python3.11/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'series?'"
     ]
    }
   ],
   "source": [
    "series_df = netflix_df[netflix_df['series?'] == 1]\n",
    "display(series_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use `groupby` to group titles that are of the same property.  In general, `groupby` combine all of the rows in a dataframe that have the same value for the column(s) that you specify.  For example, doing a `groupby` on `property` will group all of the seasons of *The Unbreakable Kimmy Schmidt* together as a single entry (and similar for other properties).\n",
    "\n",
    "When we group entries in this way, there will be some information that we want to keep and some that we will discard.  For example, we almost certainly want to keep the hours watched information (to either sum or average), but we will likely discard the release dates since there isn't a sensible way to combine the multiple release dates for the different seasons of a show. \n",
    "\n",
    "We have have to tell `pandas` which information to keep (*i.e.*, `megahours_viewed`) and how we want to combine it for the various entries.  Let's start by simply adding all of the `megahours_viewed` for the entries that we group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_df_0 = netflix_df[netflix_df['series?'] == 1]\n",
    "\n",
    "series_df_0 = series_df_0.groupby('property')['megahours_viewed'].sum().reset_index()\n",
    "series_df_0 = series_df_0.sort_values('megahours_viewed', ascending=False)\n",
    "display(series_df_0.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll count number of titles that are grouped to each property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_df_1 = netflix_df[netflix_df['series?'] == 1]\n",
    "\n",
    "series_df_1 = series_df_1.groupby('property')['Title'].count().reset_index()\n",
    "series_df_1 = series_df_1.sort_values('Title', ascending=False)\n",
    "display(series_df_1.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which confirms my suspicion that *Grey's Anatomy* has been on for tooooooo loooooooong.\n",
    "\n",
    "This looks good so far, but it's also inefficient.  What if I wanted to both count the seasons *and* sum the hours viewed?  I don't want to have to carry two separate dataframes around.\n",
    "\n",
    "### `agg`\n",
    "\n",
    "The `Dataframe.agg` function allows us to give multiple reduction instructions to `groupby`.  `agg` is short for \n",
    "> **aggregate** (/ˈaɡ rə ɡət/) *adj.*, formed or calculated by the combination of many separate units or items\n",
    "\n",
    "With `agg`, we supply a **dictionary** (you remember those, right?) of feature/function pairs.  For exmaple, I can do both of the reductions above with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_df = netflix_df[netflix_df['series?'] == 1]\n",
    "\n",
    "agg_dict = {'Title': 'count', 'megahours_viewed': 'sum'}\n",
    "\n",
    "series_df = series_df.groupby('property').agg(agg_dict).reset_index()\n",
    "series_df = series_df.sort_values('Title', ascending=False)\n",
    "display(series_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One weirdness of `agg` is that we supply *strings* of the function names!  So in the above the function named `'sum'` gets applied to the `'megahours_viewed'` column, and `count` counts the unique entries in the `Title` column.\n",
    "\n",
    "Check out what we can now do with this reduced dataset!  We'll rename one of the columns and then calculate the average viewership per season:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_df = series_df.rename(columns={'Title': 'n_seasons'})\n",
    "\n",
    "series_df['Mhv_per_season'] = series_df['megahours_viewed'] / series_df['n_seasons']\n",
    "\n",
    "display(series_df.sort_values('Mhv_per_season', ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, *The Night Agent* (which is totally a thing that I knew about for several notebook cells now) wins again!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## What about science, though?\n",
    "\n",
    "I know what you're thinking: the above examples with Netflix data were really, really, really great, but I'm trying to be a scientist over here!  How can these skills help me do science?\n",
    "\n",
    "Let's turn our attention to a large (but not nearly the whole thing) dataset from the [Sloan Digital Sky Survey](https://en.wikipedia.org/wiki/Sloan_Digital_Sky_Survey) (SDSS).  Please click that link to read through the SDSS Wikipedia entry -- it is an amazing instrument that has led to some excellent science!  The Tl;dr is that SDSS is a telescope in New Mexico that has taken spectra of over $10^6$ astronomical objects (stars, galaxies, quasars).  You're now going to analyze some of that data!  \n",
    "\n",
    "A quick aside about how we got the data you're about to analyze.  SDSS makes all of its data available to the public.  Because the data is so voluminous (many, many objects) and complicated (position information, spectra, optical images) there is a sophisticated (SQL) web interface called SkyServer that is used to select and download subsets of the data.  You can find SkyServer [here](https://skyserver.sdss.org/dr16/en/tools/search/sql.aspx). The SQL codee that I used to generate the dataset below is:\n",
    "```\n",
    "SELECT TOP 100000\n",
    "   s.specobjid, s.class, s.z as redshift,\n",
    "   s.plate, s.mjd, s.fiberid, s.ra, s.dec,\n",
    "   s.fiberid, s.zErr, s.zWarning,\n",
    "   s.subClass, s.velDisp, s.velDispErr,\n",
    "   s.spectroFlux_u, s.spectroFlux_g, s.spectroFlux_r, s.spectroFlux_i, s.spectroFlux_z,\n",
    "   s.elodieObject, s.elodieSpType, s.elodieBV\n",
    "FROM SpecObj as s\n",
    "```\n",
    "You do **not** need to know any of this, but I'm including it here for completeness.\n",
    "\n",
    "Another quick aside just to brag.  I (Mike McCracken) have several SDSS spectrometer plates in my office!  Stop by to see them!\n",
    "\n",
    "You'll find the resulting data file in `data_files/` (duh).  This is the real stuff, people!  Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss_df = pd.read_csv('data_files/SDSS_Skyserver_SQL1_2_2024_100kObjs_SpecObj.csv')\n",
    "print(sdss_df.shape)\n",
    "print(sdss_df.columns)\n",
    "display(sdss_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow!  So this dataset contains a 22 features for $1\\times10^5$ astronomical objects studied by SDSS!  (Note: You can use SkyServer to generate a file with up to $5\\times 10^5$ objects if you're feeling frisky.) \n",
    "\n",
    "For now we're going to focus on only a few of the features:\n",
    "- `specobjid` is a unique numerical identifier for each object in the dataset.  \n",
    "- `class` is a string that tells us the basic type of the object (star, galaxy, QSO).  You should Google what a 'QSO' is.\n",
    "- `subClass` is a string that gives us some more information about what the object is.\n",
    "- `redshift` is a measure of the amount by which the light in the spectrum from that object is redshifted. This quantity is given the symbol $z$ in astronomy.  More below.\n",
    "- `zErr` is the uncertainty in the measured redshift for the object.\n",
    "\n",
    "#### Astronomy crash-course (from a particle physicist)\n",
    "\n",
    "Here's a really basic idea of how this data was collected.  Scientists point SDSS at a particular object in the sky.  They collect a spectrum of the light that the object emits.  Based on the features of the spectrum, they determine the class and subclass of the object.\n",
    "\n",
    "*Redshift* is a quantity that is essential to astronomy.  The basics are the following.  Special relativity tells us that the light emitted by an object moving away from an observer will will be shifted to longer wavelengths.  For example, stars emit light at all wavelengths in the visible spectrum.  The light from a star moving away from us will be shifted to longer wavelengths.  Red is on the long-wavelength end of the visible spectrum, so we call this shifting 'redshift'.  One can determine the redshift of, say, a star through the following process:\n",
    "1. Choose a known process that is likely to happen in the star.  A good choice would be something like one of the balmer-series transitions in hydrogen.\n",
    "2. Measure the wavelength of this transition in a laboratory on Earth.  For example, the $n=4$ to $n=2$ transition in hydrogen produces a photon with wavelength $\\lambda_{emit} = 486.135\\textrm{ nm}$.\n",
    "3. Measure the wavelength of the corresponding feature in the *observed* spectrum from the star (likely by fitting).  Call this value $\\lambda_{obs}$.\n",
    "4. Calculate the redshift as $z = (\\lambda_{obs} - \\lambda_{emit})/\\lambda_{emit}$.\n",
    "\n",
    "The larger the redshift ($z$), the more difference there is between the emitted and observed wavelengths.  The larger the difference between the wavelengths, the faster the object is receding (moving away) from us (the observer).  \n",
    "\n",
    "#### Mean $z$ values for different classes of objects\n",
    "\n",
    "Let's do some grouping of this data to see if we can determine any significant differences in redshift between the different types of object.\n",
    "\n",
    "To do this, I want to show off another way to give instructions to the `agg` function.  See if you can follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss_df = pd.read_csv('data_files/SDSS_Skyserver_SQL1_2_2024_100kObjs_SpecObj.csv')\n",
    "\n",
    "sdss_df = sdss_df[sdss_df['zWarning'] == 0] # this removes objects with some suspicious features\n",
    "\n",
    "def negative_z(z):\n",
    "    if z < 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "sdss_df['negative_redshift'] = sdss_df['redshift'].apply(negative_z)\n",
    "\n",
    "sdss_df = sdss_df.groupby(['class']).agg(n_objects=('specobjid', 'count'),\n",
    "                                         redshift_mean=('redshift', 'mean'),\n",
    "                                         redshift_std=('redshift', 'std'),\n",
    "                                         redshift_min=('redshift', 'min'),\n",
    "                                         redshift_max=('redshift', 'max'),\n",
    "                                         n_negative_redshift=('negative_redshift', 'sum'),\n",
    "                                         zErr_mean=('zErr', 'mean')).reset_index()\n",
    "\n",
    "display(sdss_df.sort_values('redshift_mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It's science time!\n",
    "\n",
    "We see very different values for the redshifts of stars, galaxies, and quasars (oops, I told you what 'QSO' means).  Below are a few questions that we can investigate with this reduced data.  You should answer at least the first two (talk with your neighbors) before you move on.\n",
    "\n",
    "1. (Regular) Why is the mean redshift for most stars negative?  What does this mean about stars' motion relative to us?  Why would this number on average be negative (that is, what's the physical reason for this)?\n",
    "2. (Semi-meanie) Nearly all 66.8 thousand of the galaxies in the dataset have positive $z$, meaning that they are moving away from us.  Why?  If you can't figure this out, don't feel bad -- Einsten (yes, that Einstein) [couldn't either](https://bigthink.com/13-8/lemaitre-priest-proved-einstein-wrong/).\n",
    "3. (Meanie) By now you should have Googled what a quasar ('QSO') is.  Why do we only observe them with large redshifts?  Here's a hint: For the largest-$z$ quasar in the dataset ($z = 6.99$), the 'lookback time' is approximately $13.0$ billion years.  (I'm not going to tell you what those words mean.)\n",
    "\n",
    "You may choose to work with this dataset more in the homework, but for now I'll simply point out that each of the object classes contains a number of subclasses, for a total of 52 subclasses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss_df = pd.read_csv('data_files/SDSS_Skyserver_SQL1_2_2024_100kObjs_SpecObj.csv')\n",
    "sdss_df = sdss_df[sdss_df['zWarning'] == 0]\n",
    "sdss_df = sdss_df.groupby(['class', 'subClass']).agg(n_objects=('specobjid', 'count'),\n",
    "                                         redshift_mean=('redshift', 'mean'),\n",
    "                                         redshift_std=('redshift', 'std'),\n",
    "                                         redshift_min=('redshift', 'min'),\n",
    "                                         redshift_max=('redshift', 'max'),\n",
    "                                         zErr_mean=('zErr', 'mean')).reset_index()\n",
    "\n",
    "display(sdss_df.sort_values('redshift_mean'))\n",
    "print(sdss_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## In summary\n",
    "\n",
    "Perhaps you're an Excel expert (Chem majors, are you with me?) and during the previous lesson on `pandas` basics you thought that this approach is just too much work get you to move away from a pointy-clicky spreadsheet program.\n",
    "Today's lesson should convince you that there are some (important) ways of working with data that Excel is just not suited for.  The aggregation of the SDSS data above would have taken approximately 13.0 billion years to do in Excel, and that's assuming that Excel didn't crash when you tried to open a csv file that big (and that you paid for Excel in the first place).\n",
    "\n",
    "The tools that we've investigated above allow us to ask and answer new types of questions with data!  Hopefully they encourage you to think about science in a different way. \n",
    "\n",
    "***\n",
    "\n",
    "## Problems \n",
    "\n",
    "Your homework is to complete either (three of the numbered problems) or (the single Meanie).\n",
    "\n",
    "### Regulars\n",
    "\n",
    "1. Using the Netlfix dataset, determine the titles with top-ten highest 'freshness'.  'freshness' is defined (by me) as the hours watched divided by the 'age' of the show in days.  \n",
    "2. The Netflix dataset gives the hours watched during the first half of 2023.  Find the top-ten most-watched (duirng this period) titles that were not released during this period.\n",
    "3. What fraction of Netlfix titles are available globally?  Is there is a significant difference between viewership of globally available and non-globally available titles?\n",
    "4. You're a data scientist at Netflix.  Your boss tells you that they want to remove the quartile (25%) of titles that have the lowest viewership during this period -- it's just not worth the cost of hosting these titles!  Generate a list of these titles and write it to text file.\n",
    "\n",
    "### Semi-meanies\n",
    "\n",
    "5. Netflix dataset: Write a function that calulcates the ratio of non-Roman characters to total number of characters in a title, rounding this value to the nearest 0.01.  Apply it to the subset of the Netflix dataset that contains only series (*i.e.*, exclude movies), calling the new column `nr_ratio`.  Find the top-ten most-watched titles with `nr_ratio > 0.20`.\n",
    "6. SDSS dataset: The basic spectrographic information in the SDSS dataset can actually tell us something about the masses of the galaxies therein.  That's crazy!  The `velDisp` feature in the data is a measure of distribution of velocities of the objects (stars) in a galaxy.  A larger `velDisp` (often given the symbol $\\sigma$) means that there is a larger difference between the velocities of fastest and slowest objects.  This is actually an indirect measure of the mass of a galaxy (for complicated reasons).  Make a scatter plot of `velDisp` *vs* `redshift` (commonly called $\\sigma$ *vs* $z$) for all of the non-broadband galaxies in the dataset.  Color each datapoint according to its subclass (don't forget a legend).  Keep in mind that (because of cosmological expansion) `redshift` is a measure of how far away an object is.  What relationship do you observe between these quantities?\n",
    "\n",
    "### Meanie 1 -- Netflix Economist\n",
    "\n",
    "The quantiles information for the Netflix data suggests that the megahours watched is unevenly distributed among titles.  A small number of titles get watched a LOT (*Let's Get Divorced: Season 1*???) and others barely at all.  We can investigate this by calculating the [*Gini coefficient*](https://en.wikipedia.org/wiki/Gini_coefficient) for the data.  (Note: This is a very common practice among macroeconomists who study inequality in many different systems!  Gini coefficient is a nice, general tool!)\n",
    "Follow these steps to get your Gini coefficient.\n",
    "\n",
    "- Create a dataframe that includes all non-series titles.  That is, omit any entry that has 'series' or 'season' in its title.  There are several ways to do this; you're welcome to steal from the examples above.  How many titles are in this dataframe?\n",
    "- Create a new column that is `megahours_viewed` as we did in the examples above.\n",
    "- Determine the maximum `megahours_viewed` for the titles in the dataframe.  Call this value $v_{max}$.\n",
    "- Create a new column, `Mhv_ratio` that is each title's `megahours_viewed` divided by $v_{max}$.  Note that the maximum value of `Mhv_ratio` should be 1 and the minimum value should be close to zero.\n",
    "- Make a histogram of `Mhv_ratio`.  Your histogram should have at least 100 bins and you should manually set the range on the horizontal axis to be 0 to 1.  Before you proceed to the next step, think carefully about what this histogram tells you.\n",
    "- Now you want to scale your histogram so that the height of the tallest bar is 1.  Said another way, you want to divide the height of each bar by the height of the tallest bar.  Think back to our fitting lessons.  When you use `pyplot` to make a histogram, it outputs information about the bin edges and bar heights.  For example, you can get this information from a bit of code like\n",
    "```\n",
    "x, y, _ = plt.hist(mhv_ratio_array)\n",
    "```\n",
    "- To this scaled histogram, add a straight line that connects the points $(0,0)$ and $(1,1)$.  Calculate the area under this line.  Call it $L$.  (Hint: It's a traingle.)\n",
    "- Calculate the total area of all of the bars of your scaled histogram.  Call it $H$.  (Hint: Riemann sum.)\n",
    "- Calculate the Gini coefficient: $G = (L-H)/L$.\n",
    "- Do some googling to interpret the $G$ vaule you get.  Is it large compared to, say, inequalities in income, wealth, education, *etc.*?\n",
    "- Congrats!  You're now a macroeconomist.  (Not really.)\n",
    "\n",
    "### Meanie 2 -- Star Sleuth\n",
    "\n",
    "In this problem you will investigate the subclasses of stars in the SDSS dataset.  Astronomers classify stars using the Morgan–Keenan (MK) system, in which each star falls into one of seven classes (called O, B, A, F, G, K, and M) according to its temperature.  A star's temperature is a function of the physics going on in it, so this is a useful classification scheme.  Check out the [Wikipedia article](https://en.wikipedia.org/wiki/Stellar_classification) for more info, most importantly\n",
    "> Most stars are currently classified under the Morgan–Keenan (MK) system using the letters O, B, A, F, G, K, and M, a sequence from the hottest (O type) to the coolest (M type). Each letter class is then subdivided using a numeric digit with 0 being hottest and 9 being coolest (e.g., A8, A9, F0, and F1 form a sequence from hotter to cooler).\n",
    "\n",
    "Let's see if the quantitative data we have contains information that correlates with the star classes (or whether the star classification was done by some other means).\n",
    "\n",
    "- First, create a dataframe that contains only objects with STAR class and a subclass from the MK scheme described above.  For example, you'll need to omit subclasses such as 'M0V', 'L5.5', 'A0p', 'OB', 'WD', 'Carbon', *etc.*\n",
    "- Create a new column in the dataframe called `MK_letter` which is just the first letter of the `subClass`.\n",
    "- We can't directly determine the temperature of a star from our data, but the `spectroFlux_` features allow us indirect access.  Very simply the `spectroFlux_` features tell us how much light came from the object in particular parts of the spectrum.  For example, the `spectroFlux_r` quantity is a measure of how much of the object's light passes through SDSS's **red** filter.  By comparing several sepctroFluxes we can get an idea of the star's temperature.  (Much more information on this process is available [here](https://skyserver.sdss.org/dr1/en/proj/advanced/color/sdssfilters.asp) and on subsequent pages.)  Let's give each of these `spectroFlux_` quantities symbols like $F_g$, $F_r$, $F_u$, *etc.*  For each star in the dataframe, calculate the following relative flux differences:\n",
    "$$\n",
    "    f_{ug} = (F_u - F_g) / F_g\n",
    "$$\n",
    "$$\n",
    "    f_{gr} = (F_g - F_r) / F_r \\\\    \n",
    "$$\n",
    "- Make a scatter plot of the $f_{ug}$ *vs* $f_{gr}$ for all of the stars in your dataframe.  Color each point according the its `MK_letter`.  Don't forget to include a legend!  You will want to make your data points slightly transparent so that you can see them well.\n",
    "- Knowing what you know about the MK classification (*i.e.*, the temperature ordering of the classes) do you see a correlation between the relative flux differences and temperature?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}